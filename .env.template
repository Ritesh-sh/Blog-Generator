# Environment Configuration - Production Ready Template
# Copy this to .env and fill in your actual API keys

# =============================================================================
# LLM PROVIDER CONFIGURATION
# =============================================================================
# Choose which LLM provider to use: "openai" or "gemini"
LLM_PROVIDER=openai

# =============================================================================
# OPENAI CONFIGURATION (if LLM_PROVIDER=openai)
# =============================================================================
# Get your API key from: https://platform.openai.com/api-keys
OPENAI_API_KEY=sk-your-actual-openai-api-key-here

# Model options (cost-optimized to expensive):
# - gpt-3.5-turbo (recommended for MVP) - ~$0.002 per blog
# - gpt-4o-mini - ~$0.005 per blog
# - gpt-4 - ~$0.10 per blog (not recommended unless quality critical)
OPENAI_MODEL=gpt-3.5-turbo

# =============================================================================
# GOOGLE GEMINI CONFIGURATION (if LLM_PROVIDER=gemini)
# =============================================================================
# Get your API key from: https://makersuite.google.com/app/apikey
GEMINI_API_KEY=your-actual-gemini-api-key-here

# Model options:
# - gemini-1.5-flash (recommended for MVP) - ~$0.0001 per blog
# - gemini-1.5-pro - ~$0.001 per blog
GEMINI_MODEL=gemini-1.5-flash

# =============================================================================
# APPLICATION SETTINGS
# =============================================================================
# Environment: development, staging, production
APP_ENV=development

# Logging level: DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_LEVEL=INFO

# Maximum content length to extract from website (in characters)
# Lower = faster + cheaper, Higher = more comprehensive
# Recommended: 10000 (balances cost and quality)
MAX_CONTENT_LENGTH=10000

# HTTP request timeout in seconds
REQUEST_TIMEOUT=30

# =============================================================================
# MODEL SETTINGS (Local NLP)
# =============================================================================
# Sentence transformer model for embeddings and topic analysis
# all-MiniLM-L6-v2: Lightweight, fast, good quality (~80MB)
# Alternative: all-mpnet-base-v2 (better quality, ~420MB, slower)
EMBEDDING_MODEL=all-MiniLM-L6-v2

# Enable FAISS caching for repeated URLs (reduces processing time)
# Set to true in production if you expect repeated URLs
USE_FAISS_CACHE=false

# =============================================================================
# COST OPTIMIZATION NOTES
# =============================================================================
# For minimum cost per blog:
#   LLM_PROVIDER=gemini
#   GEMINI_MODEL=gemini-1.5-flash
#   MAX_CONTENT_LENGTH=5000
#   Expected cost: ~$0.0001 per blog
#
# For best quality (higher cost):
#   LLM_PROVIDER=openai
#   OPENAI_MODEL=gpt-4
#   MAX_CONTENT_LENGTH=15000
#   Expected cost: ~$0.10 per blog
#
# Recommended balance (MVP):
#   LLM_PROVIDER=openai
#   OPENAI_MODEL=gpt-3.5-turbo
#   MAX_CONTENT_LENGTH=10000
#   Expected cost: ~$0.002 per blog
